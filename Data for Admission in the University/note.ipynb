{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b253ede3-6abf-4737-af01-33b1c0cd9a94",
   "metadata": {},
   "source": [
    "This dataset includes various information like GRE score, TOEFL score, university rating, SOP (Statement of Purpose), LOR (Letter of Recommendation), CGPA, research and chance of admit. In this dataset, 400 entries are included.\n",
    "\n",
    "GRE Scores ( out of 340 )\n",
    "TOEFL Scores ( out of 120 )\n",
    "University Rating ( out of 5 )\n",
    "Statement of Purpose (SOP) and Letter of Recommendation (LOR) Strength ( out of 5 )\n",
    "Undergraduate GPA ( out of 10 )\n",
    "Research Experience ( either 0 or 1 )\n",
    "Chance of Admit ( ranging from 0 to 1 ).\n",
    "\n",
    "\n",
    "Bộ dữ liệu này bao gồm nhiều thông tin khác nhau như điểm GRE, điểm TOEFL, xếp hạng trường đại học, SOP (Tuyên bố mục đích), LOR (Thư giới thiệu), CGPA, nghiên cứu và cơ hội trúng tuyển. Bộ dữ liệu này bao gồm 400 mục nhập.\n",
    "\n",
    "Điểm GRE (trên thang điểm 340)\n",
    "Điểm TOEFL (trên thang điểm 120)\n",
    "Xếp hạng của trường đại học (trên thang điểm 5)\n",
    "Điểm mạnh của Tuyên bố mục đích (SOP) và Thư giới thiệu (LOR) (trên thang điểm 5)\n",
    "Điểm trung bình (GPA) bậc đại học (trên thang điểm 10)\n",
    "Kinh nghiệm nghiên cứu (0 hoặc 1)\n",
    "Cơ hội trúng tuyển (từ 0 đến 1)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b38499f0-aabc-4585-84ce-467f9700879d",
   "metadata": {},
   "source": [
    "\n",
    "Sử dụng mô hình Random Forest cho tập dữ liệu này là một lựa chọn hợp lý vì các lý do sau:\n",
    "\n",
    "1. Đặc điểm của bộ dữ liệu\n",
    "Kích thước nhỏ: Tập dữ liệu có 400 dòng và 8 đặc trưng, điều này phù hợp với Random Forest vì mô hình này không yêu cầu khối lượng dữ liệu lớn để hoạt động hiệu quả.\n",
    "Tính phi tuyến: Một số mối quan hệ giữa các đặc trưng (ví dụ: GRE, TOEFL, CGPA với \"Chance of Admit\") có thể không hoàn toàn tuyến tính. Random Forest có khả năng học các mối quan hệ phi tuyến tốt nhờ việc chia nhỏ dữ liệu thành các cây quyết định.\n",
    "\n",
    "2. Ưu điểm của Random Forest\n",
    "Hiệu quả trên các bài toán hồi quy:\n",
    "Random Forest là một mô hình ensemble, sử dụng nhiều cây quyết định để cải thiện dự đoán. Nó tính trung bình các dự đoán từ nhiều cây, giúp giảm thiểu sai số và nhiễu trong dữ liệu.\n",
    "Khả năng chống overfitting:\n",
    "Do sử dụng kỹ thuật ngẫu nhiên (random sampling và random feature selection), Random Forest giảm nguy cơ overfitting so với các mô hình như Decision Tree.\n",
    "Không cần chuẩn hóa dữ liệu:\n",
    "Random Forest không bị ảnh hưởng bởi việc dữ liệu chưa chuẩn hóa, vì mô hình này dựa trên các ngưỡng cắt (splits) thay vì độ lớn tuyệt đối của giá trị.\n",
    "Xử lý tốt các đặc trưng quan trọng:\n",
    "Random Forest có thể tự động đánh giá tầm quan trọng của các đặc trưng. Điều này rất hữu ích trong việc hiểu đặc trưng nào có tác động lớn đến dự đoán.\n",
    "\n",
    "3. So sánh với các mô hình khác\n",
    "Linear Regression:\n",
    "Mô hình này giả định mối quan hệ tuyến tính giữa đặc trưng và mục tiêu. Điều này có thể không phù hợp nếu dữ liệu có mối quan hệ phi tuyến, như trong trường hợp có nhiều yếu tố tương tác phức tạp.\n",
    "Gradient Boosting (e.g., XGBoost, LightGBM):\n",
    "Gradient Boosting có thể cho kết quả chính xác cao hơn, nhưng nó yêu cầu nhiều tài nguyên tính toán hơn và có thể dễ bị overfitting nếu không được tối ưu đúng cách.\n",
    "Neural Networks:\n",
    "Không phù hợp với tập dữ liệu nhỏ (400 dòng). Neural Networks cần nhiều dữ liệu hơn để phát huy hiệu quả và tránh overfitting.\n",
    "\n",
    "Khi nào không nên dùng Random Forest?\n",
    "Nếu dữ liệu lớn hoặc có rất nhiều đặc trưng (hàng nghìn), Random Forest có thể chậm và tốn tài nguyên.\n",
    "Khi bạn cần giải thích rõ ràng cách dự đoán của mô hình (Random Forest là mô hình \"black box\").\n",
    "\n",
    "Với tập dữ liệu hiện tại, Random Forest là một lựa chọn an toàn và đáng tin cậy để bắt đầu vì nó dễ thiết lập và thường cho kết quả tốt. Nếu bạn cần dự đoán chính xác hơn, có thể thử thêm các mô hình khác hoặc thực hiện tối ưu tham số (hyperparameter tuning)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb8f5143-0d9a-4f3c-b4af-3c236e2b6acf",
   "metadata": {},
   "source": [
    "Khi sử dụng Random Forest trong scikit-learn (RandomForestClassifier hoặc RandomForestRegressor), có nhiều tham số để điều chỉnh. Dưới đây là các tham số quan trọng và tác dụng của chúng:\n",
    "\n",
    "1. Tham số điều khiển số lượng cây và cách xây dựng cây\n",
    "n_estimators: Số lượng cây trong rừng.\n",
    "\n",
    "Tăng số cây giúp mô hình ổn định và giảm sai số ngẫu nhiên, nhưng cũng làm tăng thời gian huấn luyện.\n",
    "Giá trị mặc định: 100.\n",
    "criterion: Tiêu chí để đánh giá chất lượng tách (chỉ dùng cho RandomForestRegressor hoặc RandomForestClassifier).\n",
    "\n",
    "Với phân loại: 'gini' (Gini Impurity), 'entropy' (Information Gain).\n",
    "Với hồi quy: 'squared_error' (MSE), 'absolute_error' (MAE), hoặc 'poisson'.\n",
    "max_features: Số lượng đặc trưng được xem xét khi tìm kiếm điểm tách tốt nhất.\n",
    "\n",
    "'auto' (mặc định): Sử dụng √(số đặc trưng) cho phân loại và tất cả các đặc trưng cho hồi quy.\n",
    "'sqrt': √(số đặc trưng).\n",
    "'log2': log2(số đặc trưng).\n",
    "Giá trị nhỏ hơn giúp tăng tốc độ huấn luyện và giảm overfitting nhưng có thể làm giảm độ chính xác.\n",
    "2. Tham số kiểm soát độ sâu và kích thước cây\n",
    "max_depth: Độ sâu tối đa của cây.\n",
    "\n",
    "Hạn chế độ sâu để tránh overfitting.\n",
    "Giá trị mặc định: None (cây phát triển đến khi không thể chia nhỏ thêm).\n",
    "min_samples_split: Số lượng mẫu tối thiểu cần thiết để tách một nút.\n",
    "\n",
    "Giá trị nhỏ hơn dẫn đến cây sâu hơn, có nguy cơ overfitting.\n",
    "Giá trị mặc định: 2.\n",
    "min_samples_leaf: Số lượng mẫu tối thiểu cần có ở một nút lá.\n",
    "\n",
    "Tăng giá trị này giúp cây mượt hơn và tránh overfitting.\n",
    "Giá trị mặc định: 1.\n",
    "min_weight_fraction_leaf: Tỷ lệ trọng số tối thiểu của các mẫu ở một nút lá so với tổng trọng số.\n",
    "\n",
    "Dùng khi các mẫu được gán trọng số không đồng đều.\n",
    "3. Tham số kiểm soát ngẫu nhiên\n",
    "bootstrap: Sử dụng phương pháp bootstrap (lấy mẫu lại) để xây dựng cây.\n",
    "\n",
    "True: Lấy mẫu với hoàn trả.\n",
    "False: Sử dụng toàn bộ dữ liệu mà không bootstrap.\n",
    "random_state: Hạt giống ngẫu nhiên.\n",
    "\n",
    "Đảm bảo kết quả tái hiện được trong các lần chạy.\n",
    "4. Tham số điều khiển sự song song hóa\n",
    "n_jobs: Số lượng CPU được sử dụng để huấn luyện.\n",
    "\n",
    "-1: Sử dụng tất cả CPU khả dụng.\n",
    "Giá trị lớn hơn 0: Số CPU cụ thể.\n",
    "verbose: Cấp độ log hiển thị.\n",
    "\n",
    "0: Không hiển thị log.\n",
    "Giá trị cao hơn (1, 2, ...) hiển thị thêm chi tiết về tiến trình.\n",
    "5. Các tham số điều khiển overfitting\n",
    "max_leaf_nodes: Số lượng nút lá tối đa.\n",
    "\n",
    "Giảm giá trị này có thể giúp tránh overfitting.\n",
    "max_samples: Tỷ lệ hoặc số lượng mẫu tối đa được sử dụng để xây dựng mỗi cây (áp dụng khi bootstrap=True).\n",
    "\n",
    "Hữu ích để giảm thời gian tính toán.\n",
    "6. Các tham số quan trọng khác\n",
    "oob_score: Đánh giá mô hình dựa trên dữ liệu ngoài mẫu (out-of-bag).\n",
    "True: Sử dụng các mẫu không được chọn trong bootstrap để đánh giá.\n",
    "Ứng dụng thực tế của các tham số\n",
    "Kiểm soát tốc độ và tài nguyên:\n",
    "Giảm n_estimators, max_depth, hoặc tăng max_features nếu cần huấn luyện nhanh.\n",
    "Tránh overfitting:\n",
    "Sử dụng max_depth, min_samples_split, min_samples_leaf, và max_leaf_nodes để hạn chế độ phức tạp của cây.\n",
    "Tối ưu hóa hiệu suất:\n",
    "Điều chỉnh n_estimators, criterion, và max_features để đạt độ chính xác cao hơn.\n",
    "Song song hóa:\n",
    "Dùng n_jobs=-1 để giảm thời gian chạy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c1b6612-434a-4df9-9cbc-3c40e63c3a47",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,      # Sử dụng 200 cây\n",
    "    max_depth=15,          # Giới hạn độ sâu cây là 15\n",
    "    min_samples_split=5,   # Ít nhất 5 mẫu để tách một nút\n",
    "    min_samples_leaf=2,    # Ít nhất 2 mẫu tại mỗi lá\n",
    "    max_features='sqrt',   # Xem xét √số đặc trưng\n",
    "    bootstrap=True,        # Sử dụng bootstrap\n",
    "    n_jobs=-1,             # Tận dụng toàn bộ CPU\n",
    "    random_state=42        # Đảm bảo tái lập kết quả\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36ef7d3c-cdbd-4cea-bac7-92598c89381c",
   "metadata": {},
   "source": [
    "GridSearchCV là một công cụ mạnh mẽ trong sklearn để tìm kiếm các siêu tham số tốt nhất cho mô hình bằng cách kiểm tra trên lưới các giá trị có thể. Dưới đây là các tham số chính trong GridSearchCV và tác dụng của chúng:\n",
    "\n",
    "1. estimator\n",
    "Tác dụng:\n",
    "Xác định mô hình mà bạn muốn tối ưu hóa (ví dụ: RandomForestClassifier, RandomForestRegressor, SVC,...).\n",
    "Mô tả:\n",
    "Đây là đối tượng của mô hình học máy được sử dụng trong grid search.\n",
    "2. param_grid\n",
    "Tác dụng:\n",
    "Xác định lưới các siêu tham số (hyperparameters) và các giá trị tương ứng mà bạn muốn kiểm tra.\n",
    "Mô tả:\n",
    "Là một từ điển hoặc danh sách các từ điển với cấu trúc:\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "Mỗi khóa là tên tham số, mỗi giá trị là danh sách các giá trị cần kiểm tra.\n",
    "3. scoring\n",
    "Tác dụng:\n",
    "Chỉ định chỉ số đánh giá hiệu năng của mô hình (ví dụ: độ chính xác, MSE, MAE, R²,...).\n",
    "Mô tả:\n",
    "Mặc định là None, sẽ sử dụng phương pháp đánh giá mặc định của mô hình.\n",
    "Ví dụ:\n",
    "scoring='accuracy'  # Đối với phân loại\n",
    "scoring='neg_mean_squared_error'  # Đối với hồi quy\n",
    "4. cv\n",
    "Tác dụng:\n",
    "Xác định số lượng k trong k-fold cross-validation.\n",
    "Mô tả:\n",
    "Là số nguyên hoặc một đối tượng chia dữ liệu (splitter object như StratifiedKFold).\n",
    "Mặc định là 5 nếu không chỉ định.\n",
    "Số cv càng lớn, kết quả càng chính xác nhưng thời gian chạy lâu hơn.\n",
    "5. refit\n",
    "Tác dụng:\n",
    "Chỉ định có nên huấn luyện lại mô hình trên toàn bộ tập dữ liệu với tham số tốt nhất hay không.\n",
    "Mô tả:\n",
    "Là một giá trị boolean (True hoặc False) hoặc tên của một chỉ số đánh giá (nếu có nhiều chỉ số trong scoring).\n",
    "Mặc định là True.\n",
    "6. verbose\n",
    "Tác dụng:\n",
    "Điều chỉnh mức độ chi tiết của thông báo trong quá trình chạy.\n",
    "Mô tả:\n",
    "Là số nguyên:\n",
    "0: Không hiển thị thông báo.\n",
    "1: Hiển thị một số thông báo cơ bản.\n",
    ">1: Hiển thị chi tiết quá trình chạy.\n",
    "7. n_jobs\n",
    "Tác dụng:\n",
    "Xác định số lượng lõi CPU được sử dụng để chạy song song.\n",
    "Mô tả:\n",
    "-1: Sử dụng tất cả các lõi CPU.\n",
    "1: Chạy tuần tự.\n",
    ">1: Sử dụng số lõi CPU được chỉ định.\n",
    "8. pre_dispatch\n",
    "Tác dụng:\n",
    "Kiểm soát số lượng công việc được thực hiện song song.\n",
    "Mô tả:\n",
    "Là một chuỗi hoặc số nguyên:\n",
    "\"2*n_jobs\": Mặc định, tạo gấp đôi số công việc so với số lõi CPU.\n",
    "9. error_score\n",
    "Tác dụng:\n",
    "Xử lý lỗi khi quá trình fitting xảy ra lỗi.\n",
    "Mô tả:\n",
    "Mặc định là np.nan, nghĩa là nếu xảy ra lỗi, giá trị lỗi sẽ được trả về là NaN.\n",
    "10. return_train_score\n",
    "Tác dụng:\n",
    "Quyết định có trả về điểm số trên tập huấn luyện hay không.\n",
    "Mô tả:\n",
    "Là một giá trị boolean (True hoặc False).\n",
    "Nếu là True, kết quả trên tập huấn luyện sẽ được trả về cùng với kết quả trên tập kiểm tra.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36bb946c-ecf5-461f-bff7-d577bddde677",
   "metadata": {},
   "source": [
    "Sử dụng GridSearchCV để tìm siêu tham số tối ưu cho RandomForestRegressor:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Thiết lập lưới tham số\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Khởi tạo GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=5,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Huấn luyện\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Kết quả tốt nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)\n",
    "\n",
    "\n",
    "Kết quả\n",
    "grid_search.best_params_: Trả về tham số tốt nhất.\n",
    "grid_search.best_score_: Trả về điểm tốt nhất (theo chỉ số scoring được chỉ định)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
